{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPysumSKzBJXT5mAgrDROgN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DanishFaraaz/Deep-Learning-Projects/blob/main/12_LeNet_and_AlexNet_in_Tensorflow2_0_using_Keras.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **LeNet**"
      ],
      "metadata": {
        "id": "SBkJvTw0mDqo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "c1ZdKWd_nmWZ"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, ZeroPadding2D\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.optimizers import Adadelta"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "img_rows = x_train[0].shape[0]\n",
        "img_cols = x_train[0].shape[1]\n",
        "\n",
        "x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
        "x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
        "\n",
        "input_shape = (img_rows, img_cols, 1)\n",
        "\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "\n",
        "y_train = to_categorical(y_train)\n",
        "y_test = to_categorical(y_test)\n",
        "\n",
        "num_classes = y_test.shape[1]\n",
        "num_pixels = x_train.shape[1] * x_train.shape[2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GxQktNWJpmNV",
        "outputId": "9c2032db-3f81-41a0-acfe-0d9f155a9b8e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 1s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating LeNet model\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(6, (5,5), padding='same', input_shape=input_shape))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
        "\n",
        "model.add(Conv2D(16, (5,5), padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
        "\n",
        "model.add(Conv2D(120, (5,5), padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(120))\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "model.add(Dense(84))\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "model.add(Dense(num_classes))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer=Adadelta(), metrics=['accuracy'])\n",
        "print(model.summary())"
      ],
      "metadata": {
        "id": "aUHrO92iqaVO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7af0e9b1-9f9d-4d0d-b55a-72f6c26072e5"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 28, 28, 6)         156       \n",
            "                                                                 \n",
            " activation (Activation)     (None, 28, 28, 6)         0         \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 14, 14, 6)        0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 14, 14, 16)        2416      \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 14, 14, 16)        0         \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 7, 7, 16)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 7, 7, 120)         48120     \n",
            "                                                                 \n",
            " activation_2 (Activation)   (None, 7, 7, 120)         0         \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 3, 3, 120)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 1080)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 120)               129720    \n",
            "                                                                 \n",
            " activation_3 (Activation)   (None, 120)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 84)                10164     \n",
            "                                                                 \n",
            " activation_4 (Activation)   (None, 84)                0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 10)                850       \n",
            "                                                                 \n",
            " activation_5 (Activation)   (None, 10)                0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 191,426\n",
            "Trainable params: 191,426\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 128\n",
        "epochs = 50\n",
        "\n",
        "history = model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_data=(x_test, y_test), shuffle=True)\n",
        "\n",
        "model.save('mnist_Lenet.h5')\n",
        "\n",
        "scores = model.evaluate(x_test, y_test, verbose=1)\n",
        "print('Test loss: ', scores[0])\n",
        "print('Test accuracy: ', scores[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "giViLVmMjvx6",
        "outputId": "82586b07-b244-48fb-c189-644e2da7aa88"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 2.1418 - accuracy: 0.5026 - val_loss: 2.1135 - val_accuracy: 0.5185\n",
            "Epoch 2/50\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 2.0896 - accuracy: 0.5373 - val_loss: 2.0518 - val_accuracy: 0.5499\n",
            "Epoch 3/50\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 2.0201 - accuracy: 0.5660 - val_loss: 1.9700 - val_accuracy: 0.5847\n",
            "Epoch 4/50\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 1.9286 - accuracy: 0.5993 - val_loss: 1.8640 - val_accuracy: 0.6134\n",
            "Epoch 5/50\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 1.8125 - accuracy: 0.6255 - val_loss: 1.7324 - val_accuracy: 0.6427\n",
            "Epoch 6/50\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 1.6729 - accuracy: 0.6509 - val_loss: 1.5801 - val_accuracy: 0.6667\n",
            "Epoch 7/50\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 1.5178 - accuracy: 0.6740 - val_loss: 1.4189 - val_accuracy: 0.6889\n",
            "Epoch 8/50\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 1.3612 - accuracy: 0.6972 - val_loss: 1.2636 - val_accuracy: 0.7156\n",
            "Epoch 9/50\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 1.2160 - accuracy: 0.7249 - val_loss: 1.1262 - val_accuracy: 0.7476\n",
            "Epoch 10/50\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 1.0912 - accuracy: 0.7530 - val_loss: 1.0115 - val_accuracy: 0.7695\n",
            "Epoch 11/50\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.9876 - accuracy: 0.7741 - val_loss: 0.9179 - val_accuracy: 0.7881\n",
            "Epoch 12/50\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.9029 - accuracy: 0.7902 - val_loss: 0.8411 - val_accuracy: 0.8063\n",
            "Epoch 13/50\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.8333 - accuracy: 0.8034 - val_loss: 0.7786 - val_accuracy: 0.8179\n",
            "Epoch 14/50\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.7761 - accuracy: 0.8147 - val_loss: 0.7270 - val_accuracy: 0.8294\n",
            "Epoch 15/50\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.7281 - accuracy: 0.8243 - val_loss: 0.6838 - val_accuracy: 0.8363\n",
            "Epoch 16/50\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.6873 - accuracy: 0.8319 - val_loss: 0.6463 - val_accuracy: 0.8435\n",
            "Epoch 17/50\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.6518 - accuracy: 0.8389 - val_loss: 0.6139 - val_accuracy: 0.8503\n",
            "Epoch 18/50\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.6204 - accuracy: 0.8457 - val_loss: 0.5846 - val_accuracy: 0.8554\n",
            "Epoch 19/50\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.5928 - accuracy: 0.8515 - val_loss: 0.5589 - val_accuracy: 0.8608\n",
            "Epoch 20/50\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.5679 - accuracy: 0.8573 - val_loss: 0.5358 - val_accuracy: 0.8651\n",
            "Epoch 21/50\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.5455 - accuracy: 0.8627 - val_loss: 0.5146 - val_accuracy: 0.8702\n",
            "Epoch 22/50\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.5251 - accuracy: 0.8683 - val_loss: 0.4957 - val_accuracy: 0.8748\n",
            "Epoch 23/50\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.5067 - accuracy: 0.8725 - val_loss: 0.4783 - val_accuracy: 0.8784\n",
            "Epoch 24/50\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.4898 - accuracy: 0.8766 - val_loss: 0.4626 - val_accuracy: 0.8818\n",
            "Epoch 25/50\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.4743 - accuracy: 0.8799 - val_loss: 0.4479 - val_accuracy: 0.8846\n",
            "Epoch 26/50\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.4600 - accuracy: 0.8832 - val_loss: 0.4345 - val_accuracy: 0.8863\n",
            "Epoch 27/50\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.4467 - accuracy: 0.8865 - val_loss: 0.4217 - val_accuracy: 0.8904\n",
            "Epoch 28/50\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.4344 - accuracy: 0.8891 - val_loss: 0.4100 - val_accuracy: 0.8927\n",
            "Epoch 29/50\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.4230 - accuracy: 0.8918 - val_loss: 0.3994 - val_accuracy: 0.8961\n",
            "Epoch 30/50\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.4124 - accuracy: 0.8935 - val_loss: 0.3892 - val_accuracy: 0.8985\n",
            "Epoch 31/50\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.4023 - accuracy: 0.8961 - val_loss: 0.3796 - val_accuracy: 0.8999\n",
            "Epoch 32/50\n",
            "469/469 [==============================] - 3s 5ms/step - loss: 0.3930 - accuracy: 0.8979 - val_loss: 0.3712 - val_accuracy: 0.9013\n",
            "Epoch 33/50\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.3841 - accuracy: 0.8992 - val_loss: 0.3625 - val_accuracy: 0.9044\n",
            "Epoch 34/50\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.3757 - accuracy: 0.9011 - val_loss: 0.3546 - val_accuracy: 0.9056\n",
            "Epoch 35/50\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.3679 - accuracy: 0.9028 - val_loss: 0.3473 - val_accuracy: 0.9079\n",
            "Epoch 36/50\n",
            "469/469 [==============================] - 3s 5ms/step - loss: 0.3604 - accuracy: 0.9039 - val_loss: 0.3398 - val_accuracy: 0.9095\n",
            "Epoch 37/50\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.3533 - accuracy: 0.9057 - val_loss: 0.3331 - val_accuracy: 0.9086\n",
            "Epoch 38/50\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.3465 - accuracy: 0.9068 - val_loss: 0.3268 - val_accuracy: 0.9111\n",
            "Epoch 39/50\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.3402 - accuracy: 0.9085 - val_loss: 0.3205 - val_accuracy: 0.9124\n",
            "Epoch 40/50\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.3340 - accuracy: 0.9097 - val_loss: 0.3146 - val_accuracy: 0.9139\n",
            "Epoch 41/50\n",
            "469/469 [==============================] - 3s 5ms/step - loss: 0.3283 - accuracy: 0.9107 - val_loss: 0.3094 - val_accuracy: 0.9152\n",
            "Epoch 42/50\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.3227 - accuracy: 0.9118 - val_loss: 0.3040 - val_accuracy: 0.9168\n",
            "Epoch 43/50\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.3173 - accuracy: 0.9130 - val_loss: 0.2988 - val_accuracy: 0.9183\n",
            "Epoch 44/50\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.3122 - accuracy: 0.9145 - val_loss: 0.2938 - val_accuracy: 0.9195\n",
            "Epoch 45/50\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.3072 - accuracy: 0.9151 - val_loss: 0.2890 - val_accuracy: 0.9206\n",
            "Epoch 46/50\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.3025 - accuracy: 0.9166 - val_loss: 0.2848 - val_accuracy: 0.9206\n",
            "Epoch 47/50\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.2981 - accuracy: 0.9174 - val_loss: 0.2803 - val_accuracy: 0.9232\n",
            "Epoch 48/50\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.2936 - accuracy: 0.9184 - val_loss: 0.2759 - val_accuracy: 0.9238\n",
            "Epoch 49/50\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.2893 - accuracy: 0.9194 - val_loss: 0.2719 - val_accuracy: 0.9245\n",
            "Epoch 50/50\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.2850 - accuracy: 0.9205 - val_loss: 0.2683 - val_accuracy: 0.9244\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.2683 - accuracy: 0.9244\n",
            "Test loss:  0.26829007267951965\n",
            "Test accuracy:  0.9243999719619751\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **AlexNet**"
      ],
      "metadata": {
        "id": "S1qi-MzWl5I4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, ZeroPadding2D\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.optimizers import Adadelta\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "num_classes = 10\n",
        "y_train = to_categorical(y_train)\n",
        "y_test = to_categorical(y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0QL8RIC9kxYn",
        "outputId": "e9beba99-6aa7-48c1-fea6-49213f1dfcd4"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170498071/170498071 [==============================] - 6s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "l2_reg = 0.001\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(96, (11, 11), input_shape=x_train.shape[1:], padding='same', kernel_regularizer=l2(l2_reg)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "model.add(Conv2D(256, (5,5), padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "model.add(ZeroPadding2D((1,1)))\n",
        "model.add(Conv2D(512, (3,3), padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "model.add(ZeroPadding2D((1,1)))\n",
        "model.add(Conv2D(1024, (3,3), padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "model.add(ZeroPadding2D((1,1)))\n",
        "model.add(Conv2D(1024, (3,3), padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(3072))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(4096))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(num_classes))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "print(model.summary())\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer=Adadelta(), metrics=['accuracy'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zCQNCigtml4P",
        "outputId": "9366f543-053c-44ad-d11e-b85e8a5ba0ca"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_13 (Conv2D)          (None, 32, 32, 96)        34944     \n",
            "                                                                 \n",
            " batch_normalization_13 (Bat  (None, 32, 32, 96)       384       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_19 (Activation)  (None, 32, 32, 96)        0         \n",
            "                                                                 \n",
            " max_pooling2d_11 (MaxPoolin  (None, 16, 16, 96)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_14 (Conv2D)          (None, 16, 16, 256)       614656    \n",
            "                                                                 \n",
            " batch_normalization_14 (Bat  (None, 16, 16, 256)      1024      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_20 (Activation)  (None, 16, 16, 256)       0         \n",
            "                                                                 \n",
            " max_pooling2d_12 (MaxPoolin  (None, 8, 8, 256)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " zero_padding2d_4 (ZeroPaddi  (None, 10, 10, 256)      0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " conv2d_15 (Conv2D)          (None, 10, 10, 512)       1180160   \n",
            "                                                                 \n",
            " batch_normalization_15 (Bat  (None, 10, 10, 512)      2048      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_21 (Activation)  (None, 10, 10, 512)       0         \n",
            "                                                                 \n",
            " max_pooling2d_13 (MaxPoolin  (None, 5, 5, 512)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " zero_padding2d_5 (ZeroPaddi  (None, 7, 7, 512)        0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " conv2d_16 (Conv2D)          (None, 7, 7, 1024)        4719616   \n",
            "                                                                 \n",
            " batch_normalization_16 (Bat  (None, 7, 7, 1024)       4096      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_22 (Activation)  (None, 7, 7, 1024)        0         \n",
            "                                                                 \n",
            " zero_padding2d_6 (ZeroPaddi  (None, 9, 9, 1024)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " conv2d_17 (Conv2D)          (None, 9, 9, 1024)        9438208   \n",
            "                                                                 \n",
            " batch_normalization_17 (Bat  (None, 9, 9, 1024)       4096      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_23 (Activation)  (None, 9, 9, 1024)        0         \n",
            "                                                                 \n",
            " max_pooling2d_14 (MaxPoolin  (None, 4, 4, 1024)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_2 (Flatten)         (None, 16384)             0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 3072)              50334720  \n",
            "                                                                 \n",
            " batch_normalization_18 (Bat  (None, 3072)             12288     \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_24 (Activation)  (None, 3072)              0         \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 3072)              0         \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 4096)              12587008  \n",
            "                                                                 \n",
            " batch_normalization_19 (Bat  (None, 4096)             16384     \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_25 (Activation)  (None, 4096)              0         \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 4096)              0         \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 10)                40970     \n",
            "                                                                 \n",
            " batch_normalization_20 (Bat  (None, 10)               40        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_26 (Activation)  (None, 10)                0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 78,990,642\n",
            "Trainable params: 78,970,462\n",
            "Non-trainable params: 20,180\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 128\n",
        "epochs = 50\n",
        "\n",
        "history = model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_data=(x_test, y_test), shuffle=True)\n",
        "\n",
        "model.save('CIFAR10_AlexNet_50Epochs.h5')\n",
        "\n",
        "scores = model.evaluate(x_test, y_test, verbose=1)\n",
        "print('Test loss: ', scores[0])\n",
        "print('Test accuracy: ', scores[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tp8iQ44Nonwn",
        "outputId": "7166c8ee-003f-424e-e252-2c73fc85ac8b"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "391/391 [==============================] - 89s 196ms/step - loss: 2.1948 - accuracy: 0.2245 - val_loss: 1.8337 - val_accuracy: 0.3611\n",
            "Epoch 2/50\n",
            "391/391 [==============================] - 71s 183ms/step - loss: 1.8976 - accuracy: 0.3229 - val_loss: 1.7072 - val_accuracy: 0.4157\n",
            "Epoch 3/50\n",
            "391/391 [==============================] - 71s 182ms/step - loss: 1.7958 - accuracy: 0.3642 - val_loss: 1.6525 - val_accuracy: 0.4404\n",
            "Epoch 4/50\n",
            "391/391 [==============================] - 71s 182ms/step - loss: 1.7348 - accuracy: 0.3907 - val_loss: 1.6113 - val_accuracy: 0.4599\n",
            "Epoch 5/50\n",
            "391/391 [==============================] - 72s 185ms/step - loss: 1.6858 - accuracy: 0.4131 - val_loss: 1.5763 - val_accuracy: 0.4756\n",
            "Epoch 6/50\n",
            "391/391 [==============================] - 71s 182ms/step - loss: 1.6471 - accuracy: 0.4278 - val_loss: 1.5480 - val_accuracy: 0.4879\n",
            "Epoch 7/50\n",
            "391/391 [==============================] - 71s 182ms/step - loss: 1.6122 - accuracy: 0.4456 - val_loss: 1.5234 - val_accuracy: 0.4984\n",
            "Epoch 8/50\n",
            "391/391 [==============================] - 71s 182ms/step - loss: 1.5866 - accuracy: 0.4581 - val_loss: 1.5054 - val_accuracy: 0.5037\n",
            "Epoch 9/50\n",
            "391/391 [==============================] - 71s 182ms/step - loss: 1.5611 - accuracy: 0.4716 - val_loss: 1.4841 - val_accuracy: 0.5117\n",
            "Epoch 10/50\n",
            "391/391 [==============================] - 71s 182ms/step - loss: 1.5386 - accuracy: 0.4809 - val_loss: 1.4706 - val_accuracy: 0.5186\n",
            "Epoch 11/50\n",
            "391/391 [==============================] - 72s 185ms/step - loss: 1.5218 - accuracy: 0.4892 - val_loss: 1.4541 - val_accuracy: 0.5278\n",
            "Epoch 12/50\n",
            "391/391 [==============================] - 72s 185ms/step - loss: 1.5032 - accuracy: 0.4994 - val_loss: 1.4402 - val_accuracy: 0.5329\n",
            "Epoch 13/50\n",
            "391/391 [==============================] - 72s 185ms/step - loss: 1.4884 - accuracy: 0.5057 - val_loss: 1.4295 - val_accuracy: 0.5370\n",
            "Epoch 14/50\n",
            "391/391 [==============================] - 71s 182ms/step - loss: 1.4705 - accuracy: 0.5158 - val_loss: 1.4177 - val_accuracy: 0.5407\n",
            "Epoch 15/50\n",
            "391/391 [==============================] - 72s 185ms/step - loss: 1.4573 - accuracy: 0.5227 - val_loss: 1.4077 - val_accuracy: 0.5456\n",
            "Epoch 16/50\n",
            "391/391 [==============================] - 71s 182ms/step - loss: 1.4419 - accuracy: 0.5304 - val_loss: 1.4009 - val_accuracy: 0.5478\n",
            "Epoch 17/50\n",
            "391/391 [==============================] - 71s 182ms/step - loss: 1.4308 - accuracy: 0.5333 - val_loss: 1.3902 - val_accuracy: 0.5525\n",
            "Epoch 18/50\n",
            "391/391 [==============================] - 71s 182ms/step - loss: 1.4160 - accuracy: 0.5398 - val_loss: 1.3815 - val_accuracy: 0.5559\n",
            "Epoch 19/50\n",
            "391/391 [==============================] - 71s 182ms/step - loss: 1.4020 - accuracy: 0.5490 - val_loss: 1.3750 - val_accuracy: 0.5580\n",
            "Epoch 20/50\n",
            "391/391 [==============================] - 71s 182ms/step - loss: 1.3914 - accuracy: 0.5500 - val_loss: 1.3656 - val_accuracy: 0.5650\n",
            "Epoch 21/50\n",
            "391/391 [==============================] - 71s 182ms/step - loss: 1.3785 - accuracy: 0.5580 - val_loss: 1.3589 - val_accuracy: 0.5690\n",
            "Epoch 22/50\n",
            "391/391 [==============================] - 71s 183ms/step - loss: 1.3709 - accuracy: 0.5633 - val_loss: 1.3497 - val_accuracy: 0.5702\n",
            "Epoch 23/50\n",
            "391/391 [==============================] - 72s 185ms/step - loss: 1.3577 - accuracy: 0.5676 - val_loss: 1.3458 - val_accuracy: 0.5722\n",
            "Epoch 24/50\n",
            "391/391 [==============================] - 72s 185ms/step - loss: 1.3474 - accuracy: 0.5753 - val_loss: 1.3354 - val_accuracy: 0.5765\n",
            "Epoch 25/50\n",
            "391/391 [==============================] - 72s 185ms/step - loss: 1.3353 - accuracy: 0.5808 - val_loss: 1.3308 - val_accuracy: 0.5790\n",
            "Epoch 26/50\n",
            "391/391 [==============================] - 71s 182ms/step - loss: 1.3283 - accuracy: 0.5833 - val_loss: 1.3265 - val_accuracy: 0.5842\n",
            "Epoch 27/50\n",
            "391/391 [==============================] - 72s 185ms/step - loss: 1.3175 - accuracy: 0.5930 - val_loss: 1.3180 - val_accuracy: 0.5878\n",
            "Epoch 28/50\n",
            "391/391 [==============================] - 71s 182ms/step - loss: 1.3073 - accuracy: 0.5972 - val_loss: 1.3129 - val_accuracy: 0.5890\n",
            "Epoch 29/50\n",
            "391/391 [==============================] - 72s 184ms/step - loss: 1.2950 - accuracy: 0.6022 - val_loss: 1.3106 - val_accuracy: 0.5908\n",
            "Epoch 30/50\n",
            "391/391 [==============================] - 71s 182ms/step - loss: 1.2889 - accuracy: 0.6048 - val_loss: 1.3044 - val_accuracy: 0.5907\n",
            "Epoch 31/50\n",
            "391/391 [==============================] - 72s 185ms/step - loss: 1.2778 - accuracy: 0.6104 - val_loss: 1.2996 - val_accuracy: 0.5942\n",
            "Epoch 32/50\n",
            "391/391 [==============================] - 72s 184ms/step - loss: 1.2698 - accuracy: 0.6163 - val_loss: 1.2956 - val_accuracy: 0.5967\n",
            "Epoch 33/50\n",
            "391/391 [==============================] - 71s 182ms/step - loss: 1.2580 - accuracy: 0.6228 - val_loss: 1.2905 - val_accuracy: 0.5977\n",
            "Epoch 34/50\n",
            "391/391 [==============================] - 72s 185ms/step - loss: 1.2490 - accuracy: 0.6272 - val_loss: 1.2841 - val_accuracy: 0.6004\n",
            "Epoch 35/50\n",
            "391/391 [==============================] - 72s 185ms/step - loss: 1.2437 - accuracy: 0.6286 - val_loss: 1.2809 - val_accuracy: 0.6016\n",
            "Epoch 36/50\n",
            "391/391 [==============================] - 71s 183ms/step - loss: 1.2343 - accuracy: 0.6328 - val_loss: 1.2751 - val_accuracy: 0.6069\n",
            "Epoch 37/50\n",
            "391/391 [==============================] - 72s 184ms/step - loss: 1.2254 - accuracy: 0.6391 - val_loss: 1.2734 - val_accuracy: 0.6108\n",
            "Epoch 38/50\n",
            "391/391 [==============================] - 71s 182ms/step - loss: 1.2160 - accuracy: 0.6425 - val_loss: 1.2666 - val_accuracy: 0.6125\n",
            "Epoch 39/50\n",
            "391/391 [==============================] - 72s 185ms/step - loss: 1.2076 - accuracy: 0.6488 - val_loss: 1.2664 - val_accuracy: 0.6112\n",
            "Epoch 40/50\n",
            "391/391 [==============================] - 72s 184ms/step - loss: 1.2012 - accuracy: 0.6504 - val_loss: 1.2622 - val_accuracy: 0.6117\n",
            "Epoch 41/50\n",
            "391/391 [==============================] - 71s 183ms/step - loss: 1.1936 - accuracy: 0.6557 - val_loss: 1.2568 - val_accuracy: 0.6162\n",
            "Epoch 42/50\n",
            "391/391 [==============================] - 72s 185ms/step - loss: 1.1836 - accuracy: 0.6614 - val_loss: 1.2531 - val_accuracy: 0.6177\n",
            "Epoch 43/50\n",
            "391/391 [==============================] - 72s 185ms/step - loss: 1.1773 - accuracy: 0.6644 - val_loss: 1.2557 - val_accuracy: 0.6184\n",
            "Epoch 44/50\n",
            "391/391 [==============================] - 71s 182ms/step - loss: 1.1679 - accuracy: 0.6695 - val_loss: 1.2472 - val_accuracy: 0.6226\n",
            "Epoch 45/50\n",
            "391/391 [==============================] - 71s 182ms/step - loss: 1.1587 - accuracy: 0.6731 - val_loss: 1.2425 - val_accuracy: 0.6265\n",
            "Epoch 46/50\n",
            "391/391 [==============================] - 72s 185ms/step - loss: 1.1501 - accuracy: 0.6804 - val_loss: 1.2415 - val_accuracy: 0.6258\n",
            "Epoch 47/50\n",
            "391/391 [==============================] - 72s 185ms/step - loss: 1.1426 - accuracy: 0.6817 - val_loss: 1.2375 - val_accuracy: 0.6287\n",
            "Epoch 48/50\n",
            "391/391 [==============================] - 71s 182ms/step - loss: 1.1395 - accuracy: 0.6845 - val_loss: 1.2329 - val_accuracy: 0.6300\n",
            "Epoch 49/50\n",
            "391/391 [==============================] - 71s 182ms/step - loss: 1.1282 - accuracy: 0.6907 - val_loss: 1.2325 - val_accuracy: 0.6311\n",
            "Epoch 50/50\n",
            "391/391 [==============================] - 71s 182ms/step - loss: 1.1208 - accuracy: 0.6946 - val_loss: 1.2263 - val_accuracy: 0.6326\n",
            "313/313 [==============================] - 7s 19ms/step - loss: 1.2263 - accuracy: 0.6326\n",
            "Test loss:  1.2262667417526245\n",
            "Test accuracy:  0.6326000094413757\n"
          ]
        }
      ]
    }
  ]
}